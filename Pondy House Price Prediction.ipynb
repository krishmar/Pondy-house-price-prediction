{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08b7a2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following are fine tune scores and their parameters using GridSearchcv\n",
      "\n",
      "               model  best_score                                 best_params\n",
      "0  linear_regression    0.847796                        {'normalize': False}\n",
      "1              lasso    0.726754         {'alpha': 2, 'selection': 'random'}\n",
      "2      decision_tree    0.741284  {'criterion': 'mse', 'splitter': 'random'}\n",
      "\n",
      "\n",
      "Estimated house price of '1st Phase JP Nagar',1000, 2, 2 :  83.87  Lakhs\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "# Pondy House Price Prediction:                            #\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                             #\n",
    "# An end to End project for calculating House Price.       #\n",
    "# Sart with feature engineering - Data cleaning/wrangling  #\n",
    "# remove outliers, Hypertune parameters - build model      #\n",
    "# Finally export the pretrianed model in to an pickle file #\n",
    "############################################################\n",
    "\n",
    "# Use following lines only if you need a clean build with no warnings\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# modules for data modeling\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pickle, json\n",
    "\n",
    "# misc modules data cleaning / wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# create dataframe from available CSV file\n",
    "df1 = pd.read_csv(\"pondy_house_prices.csv\")\n",
    "# print(df1.shape)\n",
    "\n",
    "###############################################\n",
    "# ~~~~~~~~~~~~~ Data Wrangling ~~~~~~~~~~~~~~~~\n",
    "###############################################\n",
    "\n",
    "# remove uneccessary (non-supportive) features\n",
    "df2 = df1.drop(['area_type','society','balcony','availability'],axis='columns')\n",
    "df3 = df2.dropna() # remove null data\n",
    "# print(df3.shape)\n",
    "\n",
    "# remove extra chracter in 'size' feature\n",
    "df3['bhk'] = df3['size'].apply(lambda x: int(x.split(' ')[0]))\n",
    "df4 = df3.copy() \n",
    "\n",
    "# clean 'total_sqft' feature with data in range (example:1200-1800) \n",
    "def convert_sqft_to_num(x):                  \n",
    "    tokens = x.split('-')\n",
    "    if len(tokens) == 2:\n",
    "        return (float(tokens[0])+float(tokens[1]))/2\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "df4.total_sqft = df4.total_sqft.apply(convert_sqft_to_num)\n",
    "df4 = df4[df4.total_sqft.notnull()]\n",
    "df5 = df4.copy()\n",
    "# print(df5.shape)\n",
    "\n",
    "\n",
    "# create new column 'price_per_sqft' for price comparison\n",
    "df5['price_per_sqft'] = df5['price']*100000/df5['total_sqft'] \n",
    "\n",
    "# remove data in 'location' with lesser information \n",
    "df5.location = df5.location.apply(lambda x: x.strip())  \n",
    "location_stats = df5.location.value_counts(ascending=False)\n",
    "location_stats_less_than_10 = location_stats[location_stats<=10]\n",
    "df5.location = df5.location.apply(lambda x:\\\n",
    "'other' if x in location_stats_less_than_10 else x)\n",
    "\n",
    "# remove data with false BHK information.\n",
    "df6 = df5[~(df5.total_sqft/df5.bhk < 300)]\n",
    "\n",
    "###############################################\n",
    "# ~~~~~~~~~~~~~ Feature Engineering ~~~~~~~~~~~\n",
    "###############################################\n",
    "\n",
    "# remove outliers found beyond \"one-standard deviation\"\n",
    "def clean_pps_outliers(df):\n",
    "    df_out = pd.DataFrame()\n",
    "    for location, subdf in df.groupby('location'):\n",
    "        m = np.mean(subdf.price_per_sqft)\n",
    "        st = np.std(subdf.price_per_sqft)\n",
    "        reduced_df = subdf[(subdf.price_per_sqft >=(m-st))\n",
    "            & (subdf.price_per_sqft <=(m+st))]\n",
    "        df_out = pd.concat([df_out, reduced_df], ignore_index=True)\n",
    "    return df_out\n",
    "\n",
    "df7 = clean_pps_outliers(df6)\n",
    "df7.shape\n",
    "\n",
    "\n",
    "# remove outliers with mismatch in price and BHK\n",
    "def clean_bhk_outliers(df):\n",
    "    exclude_indices = np.array([])\n",
    "    for location, locationdf in df.groupby('location'):\n",
    "        bhk_stats = { }\n",
    "        for bhk, bhkdf in locationdf.groupby('bhk'):\n",
    "            bhk_stats[bhk] = {\n",
    "                'mean':np.mean(bhkdf.price_per_sqft),\n",
    "                'count':bhkdf.shape[0]\n",
    "            }\n",
    "        for bhk, bhkdf in locationdf.groupby('bhk'):\n",
    "            stats = bhk_stats.get(bhk-1)\n",
    "            if stats and stats['count'] > 5:\n",
    "                exclude_indices = np.append(exclude_indices,\\\n",
    "                bhkdf[bhkdf.price_per_sqft < stats['mean']].index.values)\n",
    "    return df.drop(exclude_indices, axis='index')\n",
    "\n",
    "df8 = clean_bhk_outliers(df7)\n",
    "\n",
    "# remove ouliers with mismatch in total bathroom and BHK informtion\n",
    "df9 = df8[df8.bath < df8.bhk+2]\n",
    "\n",
    "# finally remove non supportive features for model building\n",
    "df10 = df9.drop(['size', 'price_per_sqft'],axis='columns')\n",
    "\n",
    "# encoding location data with dummies function in pandas\n",
    "dummies = pd.get_dummies(df10.location)\n",
    "df11 = pd.concat([df10,dummies.drop('other',axis='columns')], axis='columns')\n",
    "df12 = df11.drop('location', axis='columns')\n",
    "\n",
    "###############################################\n",
    "# ~~~~~~~~~~~~~ Data Modeling ~~~~~~~~~~~~~~~~\n",
    "###############################################\n",
    "\n",
    "# final data X, y for training and testing\n",
    "X = df12.drop(['price'],axis='columns')\n",
    "y = df12.price\n",
    "\n",
    "# Hyper Parameter tunning with GridSearchCV\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "cross_val_score(LinearRegression(), X, y, cv=cv)\n",
    "\n",
    "def hyper_parameter_tune(X,y):\n",
    "    algos = {\n",
    "        'linear_regression' : {\n",
    "            'model': LinearRegression(),\n",
    "            'params': {\n",
    "                'normalize': [True, False]\n",
    "            }\n",
    "        },\n",
    "        'lasso': {\n",
    "            'model': Lasso(),\n",
    "            'params': {\n",
    "                'alpha': [1,2],\n",
    "                'selection': ['random', 'cyclic']\n",
    "            }\n",
    "        },\n",
    "        'decision_tree': {\n",
    "            'model': DecisionTreeRegressor(),\n",
    "            'params': {\n",
    "                'criterion' : ['mse','friedman_mse'],\n",
    "                'splitter': ['best','random']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    scores = []\n",
    "    cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "    for algo_name, config in algos.items():\n",
    "        gs =  GridSearchCV(config['model'], config['params'], \\\n",
    "                           cv=cv, return_train_score=False)\n",
    "        gs.fit(X,y)\n",
    "        scores.append({\n",
    "            'model': algo_name,\n",
    "            'best_score': gs.best_score_,\n",
    "            'best_params': gs.best_params_\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "\n",
    "print(\"Following are fine tune scores and their parameters using GridSearchcv\\n\")\n",
    "print(hyper_parameter_tune(X,y))\n",
    "\n",
    "# Choose LinearRegression as the best model with highest accuracy score\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=10)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "# cross check build model\n",
    "def predict_price(location,sqft,bath,bhk):    \n",
    "    loc_index = np.where(X.columns==location)[0][0]\n",
    "\n",
    "    x = np.zeros(len(X.columns))\n",
    "    x[0] = sqft\n",
    "    x[1] = bath\n",
    "    x[2] = bhk\n",
    "    if loc_index >= 0:\n",
    "        x[loc_index] = 1\n",
    "\n",
    "    return lr.predict([x])[0]\n",
    "\n",
    "Estimated_House_Price = predict_price('1st Phase JP Nagar',1000, 2, 2)\n",
    "\n",
    "print(\"\\n\\nEstimated house price of '1st Phase JP Nagar',1000, 2, 2' is : \", Estimated_House_Price.round(2), \" Lakhs\")\n",
    "\n",
    "\n",
    "##############################################################\n",
    "# ~~~~~~~~ Exporting pretrained model for production ~~~~~~~~~\n",
    "##############################################################\n",
    "\n",
    "\n",
    "with open('model.pickle','wb') as f:\n",
    "    pickle.dump(lr,f)\n",
    "\n",
    "\n",
    "import json\n",
    "columns = {\n",
    "    'data_columns' : [col.lower() for col in X.columns]\n",
    "}\n",
    "with open(\"columns.json\",\"w\") as f:\n",
    "    f.write(json.dumps(columns))\n",
    "     \n",
    "\n",
    "###############################################\n",
    "# ~~~~~~~~~~~~~ Result ouput ~~~~~~~~~~~~~~~~\n",
    "###############################################\n",
    "\n",
    "# if everything working is fine, after executing the py file you should see \n",
    "# the following result in your console window screen.\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\n",
    "# Following are fine tune scores and their parameters using GridSearchcv\n",
    "\n",
    "#                model  best_score                               best_params\n",
    "# 0  linear_regression    0.847796                      {'normalize': False}\n",
    "# 1              lasso    0.726738       {'alpha': 2, 'selection': 'cyclic'}\n",
    "# 2      decision_tree    0.716117  {'criterion': 'mse', 'splitter': 'best'}\n",
    "\n",
    "\n",
    "# Estimated house price of '1st Phase JP Nagar',1000, 2, 2 :  83.87  Lakhs\n",
    "\n",
    "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0565d0e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
